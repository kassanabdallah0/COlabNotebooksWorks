{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YUCHfUeTq3ew"},"outputs":[],"source":["!pip install fuzzywuzzy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS4Wy_cqq042"},"outputs":[],"source":["!pip install python-Levenshtein"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdUvCNmXVwhK"},"outputs":[],"source":["!pip install gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mde1RFVnq31_"},"outputs":[],"source":["!pip install spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3BRHqpUq5Uo"},"outputs":[],"source":["!python -m spacy download fr_core_news_lg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYfPVtw_dUtE"},"outputs":[],"source":["!pip install --upgrade pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyQGWUbWaMGb"},"outputs":[],"source":["!pip install modin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCPBsGwJbPoa"},"outputs":[],"source":["!pip install ray"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"executionInfo":{"elapsed":12024,"status":"ok","timestamp":1693298770266,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"2-Jxv95Vbbo6","outputId":"290d0fb5-32e0-48d6-af98-4886e7cac89e"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-29 08:46:03,636\tINFO worker.py:1621 -- Started a local Ray instance.\n"]},{"data":{"text/html":["\u003cdiv class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\"\u003e\n","    \u003cdiv style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\"\u003e\n","        \u003cdiv class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\"\u003e\n","  \u003csvg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\"\u003e\n","    \u003cg clip-path=\"url(#clip0_4338_178347)\"\u003e\n","        \u003cpath d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/\u003e\n","        \u003cpath d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/\u003e\n","    \u003c/g\u003e\n","    \u003cdefs\u003e\n","        \u003cclipPath id=\"clip0_4338_178347\"\u003e\n","            \u003crect width=\"566.93\" height=\"223.75\" fill=\"white\"/\u003e\n","        \u003c/clipPath\u003e\n","    \u003c/defs\u003e\n","  \u003c/svg\u003e\n","\u003c/div\u003e\n","\n","        \u003ctable class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\"\u003e\n","    \u003ctr\u003e\n","        \u003ctd style=\"text-align: left\"\u003e\u003cb\u003ePython version:\u003c/b\u003e\u003c/td\u003e\n","        \u003ctd style=\"text-align: left\"\u003e\u003cb\u003e3.10.12\u003c/b\u003e\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","        \u003ctd style=\"text-align: left\"\u003e\u003cb\u003eRay version:\u003c/b\u003e\u003c/td\u003e\n","        \u003ctd style=\"text-align: left\"\u003e\u003cb\u003e2.6.3\u003c/b\u003e\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \n","\u003c/table\u003e\n","\n","    \u003c/div\u003e\n","\u003c/div\u003e\n"],"text/plain":["RayContext(dashboard_url='', python_version='3.10.12', ray_version='2.6.3', ray_commit='8a434b4ee7cd48e60fa1531315d39901fac5d79e', protocol_version=None)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import ray\n","ray.init()"]},{"cell_type":"markdown","metadata":{"id":"tkhK7T0yTr14"},"source":["# Importing :\n","\n","\n","1.   **pandas** and **numpy** are used for data manipulation and analysis.\n","2. **json** is imported for working with JSON data.\n","3. **gc** stands for the garbage collector, which helps manage memory.\n","4. **os** provides functions for interacting with the operating system.\n","5. **time** is used for time-related operations.\n","6. **re** allows working with regular expressions.\n","7. **nltk** is the Natural Language Toolkit for text processing.\n","8. **logging** is for generating log messages.\n","9. **spacy** is a library for natural language processing.\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1693298775373,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"WzlsQrdeTA0d"},"outputs":[],"source":["import numpy as np\n","import json\n","import gc\n","import os\n","import time\n","import re\n","import nltk\n","import logging\n","import spacy\n","os.environ['__MODIN_AUTOIMPORT_PANDAS__'] = '1'\n","import modin.pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"ROHBLJgxpCnS"},"source":["1. **fuzzywuzzy** provides **fuzzy** string matching capabilities.\n","2. **TfidfVectorizer** and **CountVectorizer** from **sklearn**.feature_extraction.text are used for text vectorization.\n","3. **cosine_similarity** from **sklearn.metrics.pairwise** calculates cosine similarity between vectors.\n","4. **ProcessPoolExecutor** from **concurrent.futures** enables parallel processing.\n","5. **tqdm** is a library for creating progress bars during iteration.\n","6. **Word2Vec**, **WmdSimilarity**, and **KeyedVectors** from **gensim.models** are for word embedding and similarity calculations.\n","7. **google.colab** contains utilities for working in Google Colab environment.\n","8. **stopwords** and **WordNetLemmatizer** from **nltk.corpus** are used for text preprocessing.\n","9. **List** and Union from typing module provide type hints for function parameters.\n","These imports allow you to leverage various functionalities for text processing, analysis, and parallel processing."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":429,"status":"ok","timestamp":1693298776624,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"9YYBHQ5AyhCx"},"outputs":[],"source":["from fuzzywuzzy import fuzz\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import CountVectorizer\n","from concurrent.futures import ProcessPoolExecutor\n","from tqdm import tqdm\n","from gensim.models import Word2Vec\n","from gensim.similarities import WmdSimilarity\n","from gensim.models import KeyedVectors\n","from google.colab import files\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from typing import List, Union"]},{"cell_type":"markdown","metadata":{"id":"zHuq9xvgTvS_"},"source":["# Loading:"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11690,"status":"ok","timestamp":1693298788707,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"40LGW-7mzIwV"},"outputs":[],"source":["nlp = spacy.load('fr_core_news_lg')\n","# Initialize logging\n","logging.basicConfig(level=logging.INFO)\n","\n","# Define the folder path\n","folder_path = '/content/excelwork/'\n","\n","# List all files in the folder\n","all_files = os.listdir(folder_path)\n","\n","# Filter out Excel files\n","excel_files = [f for f in all_files if f.endswith('.xlsx') or f.endswith('.xls')]\n","\n","# Full paths to Excel files\n","excel_file_paths = [os.path.join(folder_path, f) for f in excel_files]"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693298788707,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"aUU5Jf98Nb91"},"outputs":[],"source":["standard_columns = np.load('/content/standard_columns.npy')\n","Type_TP = np.load('/content/Type_TP.npy')\n","INTERVENANT_OPTIONS = np.load('/content/INTERVENANT_OPTIONS.npy')\n","Typologie = np.load('/content/Typologie.npy')\n","Causes_Echecs = np.load('/content/Causes_Echecs.npy')\n","ADMIN_NAMES = np.load('/content/ADMIN_NAMES.npy')\n","OPTIONS_MAP_Stringheader = np.load('/content/OPTIONS_MAP_Stringheader.npy', allow_pickle=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693298788708,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"aHqqRrET5irN"},"outputs":[],"source":["output_xlsx_file = \"/content/combined_data.xlsx\""]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693298788708,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"BybEBcntEull"},"outputs":[],"source":["# Initialize logging with timestamp and file handler\n","logging.basicConfig(filename='excel_processing.log', level=logging.INFO,\n","                    format='%(asctime)s:%(levelname)s:%(message)s')"]},{"cell_type":"markdown","metadata":{"id":"cWsAHEXST5Nc"},"source":["# Combining Excel file Part:\n","\n","## Table of Contents\n","1. [worker](#worker)\n","2. [parallel_concat](#parallel_concat)\n","3. [find_similar_column](#find_similar_column)\n","4. [check_and_fill_missing_columns](#check_and_fill_missing_columns)\n","5. [process_combined_df](#process_combined_df)\n","6. [find_similar_file_path](#find_similar_file_path)\n","7. [process_excel_file](#process_excel_file)\n","8. [combine_excel_files_to_xlsx](#combine_excel_files_to_xlsx)\n","\n","\n","### `worker`\n","\n","**Description**:  \n","Concatenates a list of DataFrames and removes rows that are all spaces or NaNs.\n","\n","### `parallel_concat`\n","\n","**Description**:  \n","Uses parallel processing to concatenate chunks of DataFrames.\n","\n","### `find_similar_column`\n","\n","**Description**:  \n","Finds the most similar column name to a given reference column.\n","\n","### `check_and_fill_missing_columns`\n","\n","**Description**:  \n","Checks for missing columns in a DataFrame and optionally fills them.\n","\n","### `process_combined_df`\n","\n","**Description**:  \n","Combines a list of DataFrames into a single DataFrame and saves it to Excel.\n","\n","### `find_similar_file_path`\n","\n","**Description**:  \n","Finds the most similar file path to a given target path.\n","\n","### `process_excel_file`\n","\n","**Description**:  \n","Processes an Excel file into a DataFrame.\n","\n","### `combine_excel_files_to_xlsx`\n","\n","**Description**:  \n","Combines multiple Excel files into a single Excel file."]},{"cell_type":"markdown","metadata":{"id":"9LGNV4KsURIb"},"source":["## `worker`\n","\n","### Description\n","The `worker` function concatenates a list of pandas DataFrames and performs some cleaning operations.\n","\n","### Parameters\n","- **df_list (list of pd.DataFrame)**:  \n","  List of DataFrames to be concatenated.\n","\n","### Returns\n","- **pd.DataFrame**:  \n","  A single DataFrame obtained by concatenating all the DataFrames in `df_list`. The DataFrame also undergoes the following cleaning operations:\n","  - Rows containing only spaces or NaNs are removed.\n","  - The index is reset.\n","\n","### Example\n","```python\n","df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n","df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n","result = worker([df1, df2])\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693298788708,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"wi98adLdSeN8"},"outputs":[],"source":["def worker(df_list: List[pd.DataFrame]) -\u003e Union[pd.DataFrame, None]:\n","    \"\"\"\n","    Concatenates a list of DataFrames, removes rows that are all spaces or NaNs, and resets the index.\n","    Optimized for memory usage.\n","\n","    Parameters:\n","    - df_list (List[pd.DataFrame]): List of DataFrames to concatenate.\n","\n","    Returns:\n","    - pd.DataFrame or None: The concatenated DataFrame or None if an error occurs.\n","    \"\"\"\n","    try:\n","        # Initialize logging\n","        logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","        # Step 1: Concatenate DataFrames and reset the index\n","        logging.info(\"Concatenating DataFrames...\")\n","        concatenated_df = pd.concat(df_list, ignore_index=True)\n","\n","        # Clear the list to free memory\n","        del df_list\n","        gc.collect()\n","\n","        # Step 2: Remove rows that are all spaces or NaNs\n","        logging.info(\"Removing rows with all spaces or NaNs...\")\n","        concatenated_df = concatenated_df[~concatenated_df.apply(lambda row: all(str(cell).isspace() or pd.isna(cell) for cell in row), axis=1)]\n","\n","        # Step 3: Reset the index again after removing rows\n","        logging.info(\"Resetting index...\")\n","        concatenated_df.reset_index(drop=True, inplace=True)\n","\n","        # Step 4: Convert columns to more memory-efficient data types\n","        logging.info(\"Optimizing data types...\")\n","        for col in concatenated_df.columns:\n","            concatenated_df[col] = pd.to_numeric(concatenated_df[col], errors='ignore', downcast='integer')\n","\n","        logging.info(\"DataFrame successfully processed.\")\n","        return concatenated_df\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred while processing the DataFrame: {e}\")\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"dcNxamkRU-9U"},"source":["## `parallel_concat`\n","\n","### Description\n","The `parallel_concat` function performs parallel concatenation of a list of pandas DataFrames. It divides the list into smaller chunks and uses multiprocessing to concatenate them.\n","\n","### Parameters\n","- **dataframes (list of pd.DataFrame)**:  \n","  List of DataFrames to be concatenated.\n","\n","### Returns\n","- **pd.DataFrame**:  \n","  A single DataFrame obtained by concatenating all the DataFrames in the input list. The DataFrame has its index reset.\n","\n","### How It Works\n","1. Divides the list of DataFrames into chunks of 5.\n","2. Uses `ProcessPoolExecutor` for parallel processing of each chunk.\n","3. Each chunk is processed by the `worker` function to concatenate the DataFrames in that chunk.\n","4. Finally, concatenates all the chunks to form a single DataFrame.\n","\n","### Example\n","```python\n","df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n","df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n","df3 = pd.DataFrame({'A': [9, 10], 'B': [11, 12]})\n","result = parallel_concat([df1, df2, df3])"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693298788708,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"QK0-UvNUSf4c"},"outputs":[],"source":["def parallel_concat(dataframes: List[pd.DataFrame]) -\u003e pd.DataFrame:\n","    \"\"\"\n","    Concatenates a list of DataFrames in parallel, optimizing for memory usage.\n","\n","    Parameters:\n","    - dataframes (List[pd.DataFrame]): List of DataFrames to concatenate.\n","\n","    Returns:\n","    - pd.DataFrame: The concatenated DataFrame.\n","    \"\"\"\n","    # Initialize logging\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","    # Step 1: Divide the list of DataFrames into chunks of 5\n","    logging.info(\"Dividing DataFrames into chunks...\")\n","    chunks = [dataframes[i:i + 5] for i in range(0, len(dataframes), 5)]\n","\n","    concatenated_dfs = []\n","\n","    # Step 2: Use ProcessPoolExecutor for parallel processing\n","    logging.info(\"Starting parallel processing...\")\n","    with ProcessPoolExecutor() as executor:\n","        for concatenated_chunk in executor.map(worker, chunks):\n","            concatenated_dfs.append(concatenated_chunk)\n","\n","            # Clear the chunk to free memory\n","            del concatenated_chunk\n","            gc.collect()\n","\n","    # Step 3: Concatenate all the chunks and reset the index\n","    logging.info(\"Concatenating all chunks...\")\n","    final_df = pd.concat(concatenated_dfs, ignore_index=True)\n","\n","    # Clear the list to free memory\n","    del concatenated_dfs\n","    gc.collect()\n","\n","    # Step 4: Convert columns to more memory-efficient data types\n","    logging.info(\"Optimizing data types...\")\n","    for col in final_df.columns:\n","        final_df[col] = pd.to_numeric(final_df[col], errors='ignore', downcast='integer')\n","\n","    logging.info(\"DataFrames successfully concatenated.\")\n","    return final_df"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693298788708,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"Xzw3Y372SiXU"},"outputs":[],"source":["# Initialize logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')"]},{"cell_type":"markdown","metadata":{"id":"HkUL8cEPVEO8"},"source":["## `find_similar_column`\n","\n","### Description\n","The `find_similar_column` function finds the most similar column name to a given reference column name using fuzzy string matching. It uses the FuzzyWuzzy library to calculate the similarity ratio.\n","\n","### Parameters\n","- **reference_col (str)**:  \n","  The reference column name to which other column names will be compared.\n","  \n","- **columns (list of str)**:  \n","  List of column names to compare against the reference column.\n","  \n","- **similarity_threshold (int, optional)**:  \n","  The minimum similarity ratio required to consider a column as similar. Default is 80.\n","\n","### Returns\n","- **str or None**:  \n","  Returns the most similar column name if the similarity ratio is above the threshold, otherwise returns `None`.\n","\n","### How It Works\n","1. Initializes `max_similarity` to 0 and `most_similar_col` to `None`.\n","2. Iterates through each column in the `columns` list.\n","3. Calculates the similarity ratio between `reference_col` and each column.\n","4. Updates `most_similar_col` if a higher similarity ratio is found.\n","5. Returns `most_similar_col` if its similarity ratio is above the `similarity_threshold`.\n","\n","### Example\n","```python\n","reference_col = \"Name\"\n","columns = [\"name\", \"full_name\", \"first_name\"]\n","result = find_similar_column(reference_col, columns)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1693298789121,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"dNiV-Dz9SkZr"},"outputs":[],"source":["def find_similar_column(reference_col: str, columns: list, similarity_threshold: int = 80) -\u003e str:\n","    \"\"\"\n","    Finds the most similar column name to a given reference column name.\n","\n","    Parameters:\n","    - reference_col (str): The reference column name.\n","    - columns (list): List of existing column names.\n","    - similarity_threshold (int): The minimum similarity ratio to consider a match.\n","\n","    Returns:\n","    - str: The most similar column name if found, otherwise None.\n","    \"\"\"\n","    # Initialize logging\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","    max_similarity = 0\n","    most_similar_col = None\n","\n","    # Precompute the lowercase version of reference_col\n","    reference_col_lower = reference_col.lower()\n","\n","    for i, col in enumerate(columns):\n","        col_lower = str(col).lower()\n","\n","        # Calculate similarity\n","        similarity = fuzz.ratio(reference_col_lower, col_lower)\n","\n","        if similarity \u003e max_similarity:\n","            max_similarity = similarity\n","            most_similar_col = col\n","\n","            # Log the new maximum similarity found\n","            logging.info(f\"New max similarity {max_similarity} found at index {i} with column {col}.\")\n","\n","            # Early exit if 100% similarity\n","            if max_similarity == 100:\n","                logging.info(\"100% similarity found, exiting loop.\")\n","                break\n","\n","    if max_similarity \u003e similarity_threshold:\n","        logging.info(f\"Most similar column found: {most_similar_col} with similarity {max_similarity}.\")\n","        return most_similar_col\n","    else:\n","        logging.warning(f\"No similar column found with similarity above {similarity_threshold}.\")\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"3fS8DnJwVbgs"},"source":["## `check_and_fill_missing_columns` Function Documentation\n","\n","### Description\n","The `check_and_fill_missing_columns` function checks for missing columns in a DataFrame and optionally fills them with `pd.NA` values. It also looks for similar column names using fuzzy string matching if a column is missing.\n","\n","### Parameters\n","- **df (DataFrame)**:  \n","  The DataFrame to check for missing columns.\n","  \n","- **standard_columns (list of str)**:  \n","  List of standard column names that should be present in the DataFrame.\n","  \n","- **fill_missing (bool)**:  \n","  Whether to fill missing columns with `pd.NA` values. Default is `True`.\n","  \n","- **similarity_threshold (int)**:  \n","  The minimum similarity ratio required to consider a column as similar. Default is 80.\n","\n","### Returns\n","- **list of str**:  \n","  Returns a list of missing columns that were not found in the DataFrame and for which no similar columns were found.\n","\n","### How It Works\n","1. Initializes an empty list called `missing_columns`.\n","2. Iterates through each column in the `standard_columns` list.\n","3. Checks if the column is present in the DataFrame.\n","4. If not, it uses `find_similar_column` to look for a similar column.\n","5. If a similar column is found and `fill_missing` is `True`, it fills the DataFrame with `pd.NA` values for that column.\n","6. If no similar column is found, it adds the column to `missing_columns`.\n","7. Returns `missing_columns`.\n","\n","### Example\n","```python\n","df = pd.DataFrame({'name': [1, 2], 'age': [3, 4]})\n","standard_columns = ['name', 'age', 'gender']\n","result = check_and_fill_missing_columns(df, standard_columns, True, 80)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1693298790555,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"DzYP38i5Sm0V"},"outputs":[],"source":["\n","def check_and_fill_missing_columns(df: pd.DataFrame, standard_columns: list, fill_missing: bool = True, similarity_threshold: int = 80) -\u003e list:\n","    \"\"\"\n","    Checks for missing columns in the DataFrame and fills them if specified.\n","\n","    Parameters:\n","    - df (pd.DataFrame): The DataFrame to check.\n","    - standard_columns (list): List of standard column names.\n","    - fill_missing (bool): Whether to fill missing columns with NA values.\n","    - similarity_threshold (int): The minimum similarity ratio to consider a match.\n","\n","    Returns:\n","    - list: List of missing columns.\n","    \"\"\"\n","    # Initialize logging\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","    # Convert to sets for faster lookup\n","    existing_columns = set(df.columns)\n","    standard_columns_set = set(map(str, standard_columns))\n","\n","    # Initialize list to store missing columns\n","    missing_columns = []\n","\n","    for col in standard_columns_set:\n","        if col not in existing_columns:\n","            similar_col = find_similar_column(col, list(existing_columns), similarity_threshold)\n","            logging.info(f\"Similar column found: {similar_col}.\")\n","\n","            if similar_col:\n","                logging.warning(f\"Missing column in the data, but a similar column found: {col} (similar to {similar_col}).\")\n","\n","                if fill_missing:\n","                    df[col] = pd.NA\n","                    logging.debug(f\"Missing column {col} filled with NA.\")\n","            else:\n","                logging.warning(f\"Missing column in the data and no similar column found: {col}.\")\n","                missing_columns.append(col)\n","\n","    return missing_columns"]},{"cell_type":"markdown","metadata":{"id":"1krZ7cShVpVp"},"source":["## `process_combined_df`\n","\n","### Description\n","The `process_combined_df` function combines a list of DataFrames into a single DataFrame using parallel processing. It then saves the combined DataFrame to an Excel file.\n","\n","### Parameters\n","- **dataframes (list of DataFrames)**:  \n","  The list of DataFrames to be combined.\n","  \n","- **output_xlsx_file (str)**:  \n","  The name of the output Excel file where the combined DataFrame will be saved.\n","\n","### Returns\n","- **DataFrame**:  \n","  Returns the combined DataFrame if successful, otherwise returns `None`.\n","\n","### How It Works\n","1. Checks if the `dataframes` list is empty. If it is, logs an error and returns `None`.\n","2. Calls the `parallel_concat` function to concatenate the DataFrames in parallel.\n","3. Saves the combined DataFrame to an Excel file specified by `output_xlsx_file`.\n","4. Logs a success message.\n","\n","### Example\n","```python\n","df1 = pd.DataFrame({'name': ['Alice', 'Bob'], 'age': [30, 40]})\n","df2 = pd.DataFrame({'name': ['Charlie', 'David'], 'age': [50, 60]})\n","dataframes = [df1, df2]\n","output_xlsx_file = \"combined_data.xlsx\"\n","\n","result = process_combined_df(dataframes, output_xlsx_file)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693298791563,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"IyRkiNfnSpDW"},"outputs":[],"source":["def process_combined_df(dataframes: list, output_xlsx_file: str) -\u003e pd.DataFrame:\n","    \"\"\"\n","    Processes a list of DataFrames, combines them, and saves the result to an Excel file.\n","\n","    Parameters:\n","    - dataframes (list): List of DataFrames to combine.\n","    - output_xlsx_file (str): Path to the output Excel file.\n","\n","    Returns:\n","    - pd.DataFrame: The combined DataFrame.\n","    \"\"\"\n","    # Initialize logging\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","    if not dataframes:\n","        logging.error(\"No DataFrames to combine.\")\n","        return None\n","\n","    # Using parallel processing for concatenation\n","    logging.info(\"Starting to combine DataFrames...\")\n","    final_df = parallel_concat(dataframes)\n","\n","    # Save to Excel in a memory-efficient way\n","    print(output_xlsx_file)\n","    with pd.ExcelWriter(output_xlsx_file, engine='openpyxl', mode='a') as writer:\n","        final_df.to_excel(writer, index=False)\n","\n","    logging.info(\"Successfully combined DataFrames and saved to Excel.\")\n","\n","    return final_df"]},{"cell_type":"markdown","metadata":{"id":"CSY6Qot1V2gC"},"source":["## `find_similar_file_path`\n","### Description\n","The `find_similar_file_path` function searches for a file path that is similar to the given `target_path` among a list of `existing_paths`. It uses NLP-based similarity scoring to find the most similar path.\n","\n","### Parameters\n","- **target_path (str)**:  \n","  The file path you're trying to find a match for.\n","  \n","- **existing_paths (list of str)**:  \n","  The list of existing file paths to search through.\n","\n","- **similarity_threshold (float, optional)**:  \n","  The minimum similarity score to consider a path as similar. Default is 0.8.\n","\n","### Returns\n","- **str or None**:  \n","  Returns the most similar file path if a match is found, otherwise returns `None`.\n","\n","### How It Works\n","1. Converts the `target_path` and each path in `existing_paths` to NLP objects.\n","2. Calculates the similarity score between `target_path` and each existing path.\n","3. If a path with a similarity score above the `similarity_threshold` is found, it is returned.\n","4. If no such path is found, returns `None`.\n","\n","### Example\n","```python\n","target_path = \"/home/user/documents/file1.txt\"\n","existing_paths = [\"/home/user/documents/file2.txt\", \"/home/user/downloads/file1.txt\"]\n","similarity_threshold = 0.8\n","\n","result = find_similar_file_path(target_path, existing_paths, similarity_threshold)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1693298792449,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"rl4rYVSESq5c"},"outputs":[],"source":["def find_similar_file_path(target_path: str, existing_paths: list, similarity_threshold: float = 0.75) -\u003e str:\n","    \"\"\"\n","    Finds the most similar file path to the target path from a list of existing paths.\n","\n","    Parameters:\n","    - target_path (str): The target file path.\n","    - existing_paths (list): List of existing file paths.\n","    - similarity_threshold (float): The similarity threshold for considering paths as similar.\n","\n","    Returns:\n","    - str: The most similar file path, or None if no path is similar enough.\n","    \"\"\"\n","    # Initialize logging\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","    target_doc = nlp(target_path)\n","    max_similarity = 0\n","    most_similar_path = None\n","\n","    # Batch processing for efficiency\n","    path_docs = list(nlp.pipe(existing_paths))\n","\n","    for path, path_doc in zip(existing_paths, path_docs):\n","        similarity = target_doc.similarity(path_doc)\n","\n","        if similarity \u003e max_similarity:\n","            max_similarity = similarity\n","            most_similar_path = path\n","\n","            # Early exit if similarity is very high\n","            if max_similarity \u003e 0.95:\n","                logging.info(f\"High similarity found. Exiting early.\")\n","                break\n","\n","    if max_similarity \u003e similarity_threshold:\n","        return most_similar_path\n","    else:\n","        logging.warning(f\"No similar file path found with a similarity above {similarity_threshold}.\")\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"3Voi74oWWWO0"},"source":["## `process_excel_file`\n","\n","### Description\n","The `process_excel_file` function reads an Excel file, validates its columns against a list of `standard_columns`, and fills missing columns if needed. It also handles file path issues by searching for similar existing file paths.\n","\n","### Parameters\n","- **file (str)**:  \n","  The path to the Excel file to be processed.\n","  \n","- **standard_columns (list of str)**:  \n","  The list of standard column names that the DataFrame should have.\n","  \n","- **fill_missing (bool)**:  \n","  Whether to fill missing columns with `pd.NA`. Default is `True`.\n","\n","- **similarity_threshold (int)**:  \n","  The minimum similarity score to consider a column as similar. Default is 80.\n","\n","### Returns\n","- **tuple (DataFrame, bool)**:  \n","  Returns a tuple containing the processed DataFrame and a success status (`True` or `False`).\n","\n","### How It Works\n","1. Validates the file path and searches for a similar existing file path if the file does not exist.\n","2. Reads the Excel file into a DataFrame.\n","3. Checks for missing columns and fills them if `fill_missing` is `True`.\n","4. Reindexes the DataFrame based on `standard_columns`.\n","5. Returns the processed DataFrame and a success status.\n","\n","### Example\n","```python\n","file = \"data.xlsx\"\n","standard_columns = [\"Name\", \"Age\", \"Gender\"]\n","fill_missing = True\n","similarity_threshold = 80\n","\n","result = process_excel_file(file, standard_columns, fill_missing, similarity_threshold)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":344,"status":"ok","timestamp":1693298794874,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"kUm0CHs7SsvD"},"outputs":[],"source":["def process_excel_file(file, standard_columns, fill_missing, similarity_threshold):\n","    try:\n","        # Validate file path\n","        if not os.path.exists(file):\n","            logging.warning(f\"File does not exist: {file}\")\n","\n","            # Search for a similar existing file path\n","            existing_files = [f for f in os.listdir('.') if os.path.isfile(f)]\n","            logging.info('Found files: %s', existing_files)\n","            similar_file = find_similar_file_path(file, existing_files)\n","            logging.info(\"Similar file found: \" + similar_file)\n","\n","            if similar_file:\n","                logging.info(f\"Did you mean: {similar_file}? Proceeding with this file.\")\n","                file = similar_file\n","            else:\n","                logging.error(\"No similar file found.\")\n","                return (None, False)  # Ensure a tuple is returned\n","\n","        # Read and process the Excel file\n","        df = pd.read_excel(file, engine='openpyxl')  # Specify the engine\n","        logging.info('Read {} rows from Excel file'.format(len(df)))\n","        df = df.dropna(how='all')  # Remove rows that are all NaNs\n","        logging.debug('Done dropping rows')\n","\n","        # Handle date columns\n","        date_columns = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n","        print(\"Date columns: \", date_columns)\n","\n","        for col in date_columns:\n","            df[col] = df[col].dt.strftime('%Y-%m-%d')  # Convert date to string format\n","            logging.debug(f\"Date format changed for {col}.\")\n","\n","        missing_columns = check_and_fill_missing_columns(df, standard_columns, fill_missing, similarity_threshold)\n","        if missing_columns:\n","            logging.warning(f\"Missing columns in {file}: {missing_columns}.\")\n","            if fill_missing:\n","                for col in missing_columns:\n","                    df[col] = pd.NA\n","                    logging.debug(f\"Missing column {col} filled with NA.\")\n","        df = df.reindex(columns=standard_columns)\n","        logging.debug(f\"Reindexed columns in {file}.\")\n","        return (df, True)  # Return the DataFrame and success status\n","\n","    except Exception as e:\n","        logging.error(f\"Error processing Excel file {file}: {e}\")\n","        return (None, False)  # Ensure a tuple is returned"]},{"cell_type":"markdown","metadata":{"id":"dJcib9_kWjRz"},"source":["## `combine_excel_files_to_xlsx`\n","\n","### Description\n","The `combine_excel_files_to_xlsx` function combines multiple Excel files into a single Excel file. It validates each file, processes it, and then combines them. It also provides a summary report of the operation.\n","\n","### Parameters\n","- **excel_files (List[str])**:  \n","  The list of paths to the Excel files to be combined.\n","  \n","- **standard_columns (List[str])**:  \n","  The list of standard column names that each DataFrame should have.\n","  \n","- **output_xlsx_file (str)**:  \n","  The path where the combined Excel file will be saved.\n","  \n","- **fill_missing (bool)**:  \n","  Whether to fill missing columns with `pd.NA`. Default is `True`.\n","\n","- **similarity_threshold (int)**:  \n","  The minimum similarity score to consider a column as similar. Default is 80.\n","\n","### Returns\n","- **tuple (DataFrame, dict)**:  \n","  Returns a tuple containing the combined DataFrame and a summary report.\n","\n","### How It Works\n","1. Validates the input parameters.\n","2. Initializes a summary report.\n","3. Uses `ProcessPoolExecutor` for parallel processing of Excel files.\n","4. Updates the summary report based on the success or failure of processing each file.\n","5. Combines all the processed DataFrames.\n","6. Saves the combined DataFrame to an Excel file.\n","7. Returns the combined DataFrame and the summary report.\n","\n","### Example\n","```python\n","excel_files = [\"file1.xlsx\", \"file2.xlsx\"]\n","standard_columns = [\"Name\", \"Age\", \"Gender\"]\n","output_xlsx_file = \"combined.xlsx\"\n","fill_missing = True\n","similarity_threshold = 80\n","\n","result = combine_excel_files_to_xlsx(excel_files, standard_columns, output_xlsx_file, fill_missing, similarity_threshold)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693298795786,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"UrcOBOvESvoM"},"outputs":[],"source":["def combine_excel_files(excel_files, standard_columns, fill_missing, similarity_threshold, output_file_path, output_xlsx_file):\n","    #START_CODE\n","    try:\n","        # Initialize logging\n","        logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n","\n","        logging.info(\"Starting to process Excel files...\")\n","\n","        if len(excel_files) == 0 or standard_columns.size == 0 or not output_xlsx_file:\n","            logging.error(\"Invalid input parameters.\")\n","            return None\n","\n","        summary_report = {\"processed\": 0, \"skipped\": 0, \"missing_columns\": []}\n","        dataframes = []\n","\n","        with ProcessPoolExecutor() as executor:\n","            with tqdm(total=len(excel_files), desc=\"Processing files\") as pbar:\n","                for df, success in executor.map(process_excel_file, excel_files, [standard_columns]*len(excel_files), [fill_missing]*len(excel_files), [similarity_threshold]*len(excel_files)):\n","                    pbar.update(1)\n","                    if success:\n","                        dataframes.append(df)\n","                        summary_report[\"processed\"] += 1\n","                        logging.info(f\"Successfully processed file. Total processed so far: {summary_report['processed']}\")\n","                    else:\n","                        summary_report[\"skipped\"] += 1\n","                        logging.info(f\"Skipped a file. Total skipped so far: {summary_report['skipped']}\")\n","\n","        if len(dataframes) == 0:\n","            logging.error(\"No Excel files were processed. Exiting...\")\n","            return None, None\n","\n","        logging.info(\"Successfully processed Excel files. Starting to combine them...\")\n","\n","        combined_df = process_combined_df(dataframes, output_xlsx_file)\n","\n","        if not combined_df:\n","            logging.error(\"Error combining Excel files. Exiting...\")\n","            return None, None\n","\n","        logging.info(\"Successfully combined Excel files and saved to XLSX!\")\n","        logging.info(f\"Summary Report: {summary_report}\")\n","\n","        combined_df.to_excel(output_file_path, index=False)\n","\n","        return combined_df, summary_report\n","\n","    except Exception as e:\n","        logging.error(f\"Error combining Excel files: {e}\")\n","        return None, None"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1693298797001,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"NNWfH183igxS"},"outputs":[],"source":["import warnings\n","from openpyxl import Workbook\n","warnings.simplefilter(\"ignore\", category=DeprecationWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ma2KwWdX7HkA"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rProcessing files:   0%|          | 0/13 [00:00\u003c?, ?it/s]UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n","UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"]}],"source":["# Call the combine_excel_files_to_xlsx function\n","result = combine_excel_files(excel_file_paths, standard_columns, fill_missing=True,output_file_path='/content/', output_xlsx_file = 'combine_data.xlsx', similarity_threshold = 0.75)\n","\n","# Check if the result is not None\n","if result is not None:\n","    combined_df, summary_report = result\n","\n","    # Print the result tuple for debugging\n","    print(\"Result:\", result)\n","\n","    # Check if there are any errors in the summary_report\n","    if summary_report and summary_report[\"skipped\"] == 0:\n","        # Now, you can safely use head() on the combined DataFrame\n","        print(combined_df.head())\n","    else:\n","        print(\"There were errors or skipped files in combining Excel files.\")\n","else:\n","    # Handle the case where there was an error in combining the files\n","    print(\"There was an error in combining Excel files.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1693296519841,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"GKLTDt5_5qyh"},"outputs":[],"source":["df = combined_df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1693296519842,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"_wMfvXLvlfa0"},"outputs":[],"source":["manual_replacements = {\n","    \"FTTH\":'ZMD SFR',\n","    \"FTTB\":'ZMD SFR',\n","    \"B2B ACCES\": 'B2B',\n","    \"SQUALUM\":'ZMD SFR',\n","    \"TRANSFO CABLE\":'ZMD SFR'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1693296519842,"user":{"displayName":"kassan abdallah","userId":"09488167868861802107"},"user_tz":-120},"id":"Ip_7UYrZVNes"},"outputs":[],"source":[" #Configure logging\n","logging.basicConfig(filename='matching_log.log', level=logging.INFO,\n","                    format='%(asctime)s - %(levelname)s - %(message)s')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM6wWZ7OrVFE"},"outputs":[],"source":["nlp = spacy.load('fr_core_news_lg')"]},{"cell_type":"markdown","metadata":{"id":"VaTlhochm0Mj"},"source":["# Transforming Data Part :\n","\n","# Text Similarity Analysis Toolbox\n","\n","This toolbox provides a set of functions for analyzing text similarity, comparing values, and processing text data for natural language analysis.\n","\n","## `remove_numbers_from_value(input_value)`\n","\n","Remove numbers from a given input value.\n","\n","### Parameters:\n","\n","- `input_value` (numeric or string): The input value from which numbers will be removed.\n","\n","### Output:\n","\n","The function returns a string where all numeric characters have been removed from the `input_value`.\n","\n","## `preprocess(text)`\n","\n","Preprocess text data for natural language analysis.\n","\n","### Parameters:\n","\n","- `text` (string): The input text to be preprocessed.\n","\n","### Output:\n","\n","The function returns a processed string that has undergone preprocessing steps, including removing telephone numbers, tokenization, and stopword removal.\n","\n","## `jaccard_similarity(str1, str2)`\n","\n","Calculate the Jaccard similarity between two strings.\n","\n","### Parameters:\n","\n","- `str1` (string): The first input string.\n","- `str2` (string): The second input string.\n","\n","### Output:\n","\n","The function returns a value between 0 and 1, representing the Jaccard similarity between the input strings.\n","\n","## `compute_jaccard_similarities(processed_value, compare_array)`\n","\n","Compute Jaccard similarities between a processed value and an array of comparison texts.\n","\n","### Parameters:\n","\n","- `processed_value` (string): The processed value for which Jaccard similarities will be computed against the comparison texts.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Output:\n","\n","The function returns a NumPy array containing Jaccard similarity scores between the `processed_value` and each text in the `compare_array`.\n"]},{"cell_type":"markdown","metadata":{"id":"5d3a22s8lxGq"},"source":["## `summary_report(results_df, threshold)`\n","\n","Generate a summary report based on the results from the provided DataFrame.\n","\n","### Parameters:\n","\n","- `results_df` (DataFrame): The DataFrame containing the results to be summarized.\n","- `threshold` (numeric): The threshold used for matching values.\n","\n","### Description:\n","\n","This function generates a summary report based on the provided DataFrame `results_df` and the specified `threshold`. It calculates and displays various statistics related to the matched and unmatched values in the DataFrame.\n","\n","### Parameters:\n","\n","- `results_df` (DataFrame): The DataFrame containing the results to be summarized.\n","- `threshold` (numeric): The threshold used for matching values.\n","\n","### Output:\n","\n","The function prints out the following information to the console:\n","\n","- Total rows processed: The total number of rows in the `results_df`.\n","- Threshold used: The specified threshold value.\n","- Total matched values: The count of matched values in the `results_df`.\n","- Total unmatched values: The count of unmatched values in the `results_df`.\n","\n","If the `results_df` is `None`, a warning message will be logged indicating that there are no results to report. If an error occurs during the process, an error message will be logged with details about the error.\n","\n","### Example Usage:\n","\n","```python\n","import pandas as pd\n","\n","# Create a sample DataFrame\n","data = {'matched_value': [10, 20, None, 30, 40]}\n","results_df = pd.DataFrame(data)\n","\n","# Call the summary_report function\n","threshold = 25\n","summary_report(results_df, threshold)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZpW4VJsPos0"},"outputs":[],"source":["def summary_report(results_df, threshold):\n","    try:\n","        if results_df is not None:\n","            total_rows = results_df.shape[0]\n","            matched_values = results_df['matched_value'].count()\n","            unmatched_values = results_df['matched_value'].isna().sum()\n","\n","            logging.info(\"Summary Report:\")\n","            logging.info(f\"Total rows processed: {total_rows}\")\n","            logging.info(f\"Threshold used: {threshold}\")\n","            logging.info(f\"Total matched values: {matched_values}\")\n","            logging.info(f\"Total unmatched values: {unmatched_values}\")\n","        else:\n","            logging.warning(\"Summary Report: No results to report.\")\n","    except Exception as e:\n","        logging.error(f\"An error occurred while generating the summary report: {str(e)}\")"]},{"cell_type":"markdown","metadata":{"id":"CGPUWErKl2Rr"},"source":["## `remove_numbers_from_value(input_value)`\n","\n","Remove numbers from a given input value.\n","\n","### Parameters:\n","\n","- `input_value` (numeric or string): The input value from which numbers will be removed.\n","\n","### Description:\n","\n","This function takes an input value, which can be either a numeric value or a string containing numeric characters. It then removes all numeric characters from the input value and returns the result as a string.\n","\n","### Parameters:\n","\n","- `input_value` (numeric or string): The input value from which numbers will be removed.\n","\n","### Output:\n","\n","The function returns a string where all numeric characters have been removed from the `input_value`.\n","\n","### Example Usage:\n","\n","```python\n","# Call the remove_numbers_from_value function\n","input_value = \"Hello123World456\"\n","result = remove_numbers_from_value(input_value)\n","print(result)  # Output: \"HelloWorld\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqRz0oW0l0Sj"},"outputs":[],"source":["def remove_numbers_from_value(input_value):\n","    # Convert the input_value to a string\n","    input_str = str(input_value)\n","\n","    # Initialize an empty string to store the result\n","    result_str = \"\"\n","\n","    # Loop through each character in the input string\n","    for char in input_str:\n","        # Check if the character is not a digit (i.e., not a number)\n","        if not char.isdigit():\n","            # If it's not a number, add it to the result string\n","            result_str += char\n","\n","    return result_str"]},{"cell_type":"markdown","metadata":{"id":"aSW2GAVpl8V6"},"source":["## `preprocess(text)`\n","\n","Preprocess text data for natural language analysis.\n","\n","### Parameters:\n","\n","- `text` (string): The input text to be preprocessed.\n","\n","### Description:\n","\n","This function takes a text input and performs preprocessing steps to prepare it for natural language analysis. It removes telephone numbers, tokenizes the text using spaCy for proper natural language handling, and removes stopwords.\n","\n","### Parameters:\n","\n","- `text` (string): The input text to be preprocessed.\n","\n","### Output:\n","\n","The function returns a processed string that has undergone the following preprocessing steps:\n","\n","1. Removing telephone numbers using regular expressions.\n","2. Tokenizing the text using spaCy to handle natural language effectively.\n","3. Removing stopwords from the tokenized text.\n","\n","### Example Usage:\n","\n","```python\n","import spacy\n","\n","# Load the spaCy language model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Call the preprocess function\n","input_text = \"Hello, my phone number is 123-456-7890.\"\n","processed_result = preprocess(input_text)\n","print(processed_result)  # Output: \"Hello , phone number .\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCMEQE3wl691"},"outputs":[],"source":["\n","def preprocess(text):\n","    if pd.isnull(text) or text is np.nan:  # Checking for NaN values\n","        return ''\n","\n","    # Use regular expressions to remove telephone numbers\n","    text_str = remove_numbers_from_value(text)\n","    print(text_str)\n","    # Tokenize using spaCy to handle natural language properly\n","    tokens = nlp(text_str)\n","    processed_text = ' '.join([token.text for token in tokens if not token.is_stop])  # Remove stopwords\n","    return processed_text\n"]},{"cell_type":"markdown","metadata":{"id":"lG7PAWT-l_h7"},"source":["## `jaccard_similarity(str1, str2)`\n","\n","Calculate the Jaccard similarity between two strings.\n","\n","### Parameters:\n","\n","- `str1` (string): The first input string.\n","- `str2` (string): The second input string.\n","\n","### Description:\n","\n","This function calculates the Jaccard similarity between two input strings `str1` and `str2`. Jaccard similarity is a measure of how similar two sets are, and it is calculated as the size of the intersection of the sets divided by the size of their union.\n","\n","### Parameters:\n","\n","- `str1` (string): The first input string.\n","- `str2` (string): The second input string.\n","\n","### Output:\n","\n","The function returns a value between 0 and 1, representing the Jaccard similarity between the input strings. A higher value indicates greater similarity.\n","\n","### Example Usage:\n","\n","```python\n","# Call the jaccard_similarity function\n","string1 = \"apple banana orange\"\n","string2 = \"banana orange kiwi\"\n","similarity_score = jaccard_similarity(string1, string2)\n","print(similarity_score)  # Output: A value between 0 and 1 indicating similarity.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdQIRg5ymBOW"},"outputs":[],"source":["def jaccard_similarity(str1, str2):\n","    set1, set2 = set(str1.split()), set(str2.split())\n","    return len(set1 \u0026 set2) / len(set1 | set2)"]},{"cell_type":"markdown","metadata":{"id":"PvsVRBxXmHkE"},"source":["## `compute_jaccard_similarities(processed_value, compare_array)`\n","\n","Compute Jaccard similarities between a processed value and an array of comparison texts.\n","\n","### Parameters:\n","\n","- `processed_value` (string): The processed value for which Jaccard similarities will be computed against the comparison texts.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Description:\n","\n","This function calculates Jaccard similarities between a single processed value and an array of comparison texts. It utilizes the previously defined `jaccard_similarity` function to measure the similarity between the processed value and each text in the comparison array.\n","\n","### Parameters:\n","\n","- `processed_value` (string): The processed value for which Jaccard similarities will be computed against the comparison texts.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Output:\n","\n","The function returns a NumPy array containing Jaccard similarity scores between the `processed_value` and each text in the `compare_array`. Each score is a value between 0 and 1, indicating the similarity between the processed value and a specific comparison text.\n","\n","### Example Usage:\n","\n","```python\n","# Call the compute_jaccard_similarities function\n","processed_value = \"apple banana orange\"\n","comparison_texts = [\"banana orange kiwi\", \"grapes orange apple\", \"kiwi lemon lime\"]\n","similarities = compute_jaccard_similarities(processed_value, comparison_texts)\n","print(similarities)  # Output: NumPy array of similarity scores.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6NnL2TGmFPT"},"outputs":[],"source":["def compute_jaccard_similarities(processed_value, compare_array):\n","    return np.array([jaccard_similarity(processed_value, compare_text) for compare_text in compare_array])"]},{"cell_type":"markdown","metadata":{"id":"Wq4FbV9PmMeC"},"source":["## `process_row(row, columns_names, compare_tfidf, vectorizer, threshold, compare_array)`\n","\n","Process a row of data and calculate hybrid similarities for multiple columns.\n","\n","### Parameters:\n","\n","- `row` (pandas Series): The row of data to be processed.\n","- `columns_names` (list): List of column names to process.\n","- `compare_tfidf` (scipy.sparse matrix): TF-IDF matrix for comparison texts.\n","- `vectorizer` (TfidfVectorizer): TF-IDF vectorizer instance used for transforming processed values.\n","- `threshold` (float): Similarity threshold for considering matches.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Description:\n","\n","This function processes a row of data by calculating hybrid similarities between the values in the specified columns and the comparison texts. It uses a combination of cosine similarity and Jaccard similarity to determine the level of similarity. The most similar value from the comparison array is identified and returned if the similarity score exceeds the threshold.\n","\n","### Parameters:\n","\n","- `row` (pandas Series): The row of data to be processed.\n","- `columns_names` (list): List of column names to process.\n","- `compare_tfidf` (scipy.sparse matrix): TF-IDF matrix for comparison texts.\n","- `vectorizer` (TfidfVectorizer): TF-IDF vectorizer instance used for transforming processed values.\n","- `threshold` (float): Similarity threshold for considering matches.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Output:\n","\n","The function returns a list of tuples, each containing the following information:\n","\n","- Column name: The name of the processed column.\n","- Original value: The value from the processed row.\n","- Most similar value: The most similar value from the comparison array.\n","- Similarity score: The hybrid similarity score, expressed as a percentage.\n","\n","### Example Usage:\n","\n","```python\n","# Call the process_row function\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Sample data setup (replace with actual data)\n","data = pd.DataFrame({'column1': ['apple banana', 'orange kiwi'],\n","                     'column2': ['grapes pear', 'kiwi lemon']})\n","\n","compare_texts = [\"banana orange kiwi\", \"grapes orange apple\", \"kiwi lemon lime\"]\n","compare_tfidf = vectorizer.transform(compare_texts)\n","threshold = 0.5\n","\n","results = process_row(data.iloc[0], ['column1', 'column2'], compare_tfidf, vectorizer, threshold, compare_texts)\n","print(results)  # Output: List of similarity results for each column.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fztEkPpLmNFx"},"outputs":[],"source":["def process_row(row, columns_names, compare_tfidf, vectorizer, threshold, compare_array):\n","    results = []\n","    for column_name in columns_names:\n","        value = row[column_name]\n","        processed_value = preprocess(value)\n","        if processed_value == '':\n","            continue\n","\n","        tfidf_value = vectorizer.transform([processed_value])\n","        cosine_sim = cosine_similarity(tfidf_value, compare_tfidf, dense_output=True)[0]\n","        jaccard_sim = compute_jaccard_similarities(processed_value, compare_array)\n","\n","        if cosine_sim.shape != jaccard_sim.shape:\n","            continue\n","\n","        hybrid_similarity = (cosine_sim + jaccard_sim) / 2\n","        max_similarity_index = np.argmax(hybrid_similarity)\n","        similarity_score = hybrid_similarity[max_similarity_index]\n","\n","        if similarity_score \u003c threshold:\n","            continue\n","\n","        most_similar_value = compare_array[max_similarity_index]\n","        results.append((column_name, value, most_similar_value, f'{similarity_score * 100:.2f}%'))\n","    return results\n"]},{"cell_type":"markdown","metadata":{"id":"CfBKrfXumWFD"},"source":["## `process_chunk(chunk, columns_names, compare_tfidf, vectorizer, threshold, compare_array)`\n","\n","Process a chunk of data and calculate hybrid similarities for multiple rows.\n","\n","### Parameters:\n","\n","- `chunk` (pandas DataFrame): A chunk of data to be processed.\n","- `columns_names` (list): List of column names to process.\n","- `compare_tfidf` (scipy.sparse matrix): TF-IDF matrix for comparison texts.\n","- `vectorizer` (TfidfVectorizer): TF-IDF vectorizer instance used for transforming processed values.\n","- `threshold` (float): Similarity threshold for considering matches.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Description:\n","\n","This function processes a chunk of data by iterating through the rows and calculating hybrid similarities between the values in the specified columns and the comparison texts. It utilizes the previously defined `process_row` function to compute similarities for each row within the chunk.\n","\n","### Parameters:\n","\n","- `chunk` (pandas DataFrame): A chunk of data to be processed.\n","- `columns_names` (list): List of column names to process.\n","- `compare_tfidf` (scipy.sparse matrix): TF-IDF matrix for comparison texts.\n","- `vectorizer` (TfidfVectorizer): TF-IDF vectorizer instance used for transforming processed values.\n","- `threshold` (float): Similarity threshold for considering matches.\n","- `compare_array` (array-like): An array of comparison texts.\n","\n","### Output:\n","\n","The function returns a list of tuples, each containing the similarity results for each row within the chunk. Each tuple includes the following information:\n","\n","- Column name: The name of the processed column.\n","- Original value: The value from the processed row.\n","- Most similar value: The most similar value from the comparison array.\n","- Similarity score: The hybrid similarity score, expressed as a percentage.\n","\n","### Example Usage:\n","\n","```python\n","# Call the process_chunk function\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from tqdm import tqdm\n","\n","# Sample data setup (replace with actual data)\n","data = pd.DataFrame({'column1': ['apple banana', 'orange kiwi'],\n","                     'column2': ['grapes pear', 'kiwi lemon']})\n","\n","compare_texts = [\"banana orange kiwi\", \"grapes orange apple\", \"kiwi lemon lime\"]\n","compare_tfidf = vectorizer.transform(compare_texts)\n","threshold = 0.5\n","\n","chunk_size = 1000\n","chunk_generator = pd.read_csv('large_data.csv', chunksize=chunk_size)\n","\n","for chunk in chunk_generator:\n","    results = process_chunk(chunk, ['column1', 'column2'], compare_tfidf, vectorizer, threshold, compare_texts)\n","    # Process or save the results as needed\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-Z4qjlrmVlr"},"outputs":[],"source":["def process_chunk(chunk, columns_names, compare_tfidf, vectorizer, threshold, compare_array):\n","    print(f\"Starting processing of chunk...\")\n","    results = []\n","    for index, row in tqdm(chunk.iterrows(), total=chunk.shape[0]):\n","        results.extend(process_row(row, columns_names, compare_tfidf, vectorizer, threshold, compare_array))\n","\n","    print(f\"Finished processing of chunk.\")\n","    return results\n"]},{"cell_type":"markdown","metadata":{"id":"ydPlrtczmePp"},"source":["## `fit_vectorizer(compare_array)`\n","\n","Fit a TF-IDF vectorizer on a given array of texts.\n","\n","### Parameters:\n","\n","- `compare_array` (array-like): An array of texts to fit the TF-IDF vectorizer.\n","\n","### Description:\n","\n","This function fits a TF-IDF vectorizer on a provided array of texts. The vectorizer learns the vocabulary and calculates the TF-IDF weights for the words in the texts, enabling further text processing and similarity calculations.\n","\n","### Parameters:\n","\n","- `compare_array` (array-like): An array of texts to fit the TF-IDF vectorizer.\n","\n","### Output:\n","\n","The function returns a tuple containing the following:\n","\n","- `vectorizer` (TfidfVectorizer): The fitted TF-IDF vectorizer instance.\n","- `compare_tfidf` (scipy.sparse matrix): The TF-IDF matrix for the comparison texts after transformation.\n","\n","### Example Usage:\n","\n","```python\n","# Call the fit_vectorizer function\n","compare_texts = [\"banana orange kiwi\", \"grapes orange apple\", \"kiwi lemon lime\"]\n","vectorizer, compare_tfidf = fit_vectorizer(compare_texts)\n","print(vectorizer)  # Output: Fitted TF-IDF vectorizer instance.\n","print(compare_tfidf)  # Output: TF-IDF matrix for comparison texts.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adYnx61_mcK4"},"outputs":[],"source":["def fit_vectorizer(compare_array):\n","    print(\"Fitting the TF-IDF vectorizer...\")\n","    vectorizer = TfidfVectorizer()\n","    compare_tfidf = vectorizer.fit_transform(compare_array)\n","    return vectorizer, compare_tfidf\n"]},{"cell_type":"markdown","metadata":{"id":"dtEkqeqbmjWC"},"source":["## `compare_values(compare_array, df, columns_names, chunk_size=500, threshold=0.1, parallel=True)`\n","\n","Compare values in a DataFrame with a given array of texts using parallel processing.\n","\n","### Parameters:\n","\n","- `compare_array` (array-like): An array of comparison texts.\n","- `df` (pandas DataFrame): The DataFrame containing the values to compare.\n","- `columns_names` (list): List of column names to compare.\n","- `chunk_size` (int, optional): The number of rows to process per chunk. Default is 500.\n","- `threshold` (float, optional): Similarity threshold for considering matches. Default is 0.1.\n","- `parallel` (bool, optional): Whether to use parallel processing. Default is True.\n","\n","### Description:\n","\n","This function compares values in a DataFrame with a given array of comparison texts. It uses the provided `process_chunk` function to process data chunks, enabling efficient parallel or sequential comparison of values.\n","\n","### Parameters:\n","\n","- `compare_array` (array-like): An array of comparison texts.\n","- `df` (pandas DataFrame): The DataFrame containing the values to compare.\n","- `columns_names` (list): List of column names to compare.\n","- `chunk_size` (int, optional): The number of rows to process per chunk. Default is 500.\n","- `threshold` (float, optional): Similarity threshold for considering matches. Default is 0.1.\n","- `parallel` (bool, optional): Whether to use parallel processing. Default is True.\n","\n","### Output:\n","\n","The function returns a pandas DataFrame containing the following columns:\n","\n","- `column_name`: The name of the processed column.\n","- `value`: The value from the processed row.\n","- `matched_value`: The most similar value from the comparison array.\n","- `similarity_percentage`: The hybrid similarity score, expressed as a percentage.\n","\n","### Example Usage:\n","\n","```python\n","# Call the compare_values function\n","import pandas as pd\n","\n","# Sample data setup (replace with actual data)\n","data = pd.DataFrame({'column1': ['apple banana', 'orange kiwi'],\n","                     'column2': ['grapes pear', 'kiwi lemon']})\n","\n","compare_texts = [\"banana orange kiwi\", \"grapes orange apple\", \"kiwi lemon lime\"]\n","result_df = compare_values(compare_texts, data, ['column1', 'column2'])\n","print(result_df)  # Output: DataFrame containing similarity results.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgYr44JQmhTD"},"outputs":[],"source":["def compare_values(compare_array, df, columns_names, chunk_size=500, threshold=0.1, parallel=True):\n","    print(\"Starting comparison of values...\")\n","    compare_array = [preprocess(val) for val in compare_array]\n","    columns_names = [preprocess(col) for col in columns_names]  # Preprocess column_names as well\n","    vectorizer, compare_tfidf = fit_vectorizer(compare_array)\n","\n","    total_rows = df.shape[0]\n","    chunks = np.array_split(df, np.ceil(total_rows / chunk_size))\n","    print(f\"Total rows: {total_rows}, total chunks to process: {len(chunks)}.\")\n","    results = []\n","\n","    if parallel:\n","        print(\"Processing in parallel...\")\n","        with ProcessPoolExecutor() as executor:\n","            futures = [executor.submit(process_chunk, chunk, columns_names, compare_tfidf, vectorizer, threshold, compare_array)\n","                       for chunk in tqdm(chunks)]\n","            for future in tqdm(futures, desc=\"Processing chunks\"):\n","                results.extend(future.result())\n","    else:\n","        print(\"Processing sequentially...\")\n","        for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n","            results.extend(process_chunk(chunk, columns_names, compare_tfidf, vectorizer, threshold, compare_array))\n","\n","    print(\"Finished comparison of values.\")\n","    result_df = pd.DataFrame(results, columns=['column_name', 'value', 'matched_value', 'similarity_percentage'])\n","    return result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwzuBx5trCUb"},"outputs":[],"source":["total_arrays = [Type_TP]+[INTERVENANT_OPTIONS]+[Typologie]+[Causes_Echecs]+[ADMIN_NAMES]+OPTIONS_MAP_Stringheader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaimvaIoruqj"},"outputs":[],"source":["np_array = np.array(total_arrays)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCzuoZSJsKs0"},"outputs":[],"source":["np_array_f = np.hstack(np_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcaLbePIsVbc"},"outputs":[],"source":["columns_names = [\"Priorit\",\"Primtre\",\"Typologie\",\"Type TP\",\"CDP SFR\",\"CDP KEOS\",\"HO/HNO\",\"Heure TP\",\"ADMIN\", \"Nom de l'admin\",\"STIT\",\"Intervenant Terrain\",\"Statut TP\",\"Responsable echec\",\"Causes Echecs\",\"Livraison CR\",\"Cloture AP Axis\",\"Statut Attachement STIT\",\"Statut PV SFR\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwK-jKrxslGU"},"outputs":[],"source":["result_df = compare_values(INTERVENANT_OPTIONS, df, [columns_names[11]])\n","threshold = 0.1\n","summary_report(result_df, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5XYjzLswLbU"},"outputs":[],"source":["result_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-DbG-hQwTGW"},"outputs":[],"source":["result_df.to_excel('result.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nKy95rxEy_Z"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNRHgnr2J4OHLHZQ298mF3s","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}