{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPtidK7xkhOAs/HCNTGlJwY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R_HWw0Vk068M"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, PReLU, Lambda, Conv2DTranspose, LeakyReLU, Flatten, Dense, GlobalMaxPooling2D, Activation, Layer\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","source":["!unzip /content/archive.zip -d /content/;"],"metadata":{"id":"FijP8E-i1E24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SubpixelConv2D(Layer):\n","    def __init__(self, scale, **kwargs):\n","        super(SubpixelConv2D, self).__init__(**kwargs)\n","        self.scale = scale\n","\n","    def call(self, inputs):\n","        return tf.nn.depth_to_space(inputs, self.scale)\n","\n","    def get_config(self):\n","        config = super(SubpixelConv2D, self).get_config()\n","        config['scale'] = self.scale\n","        return config"],"metadata":{"id":"yJOSOvfU1ZjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def residual_block(inputs):\n","    x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    output = Add()([x, inputs])\n","    output = Activation('relu')(output)\n","    return output\n","\n","def upscale_block(inputs):\n","    x = Conv2D(filters=1024, kernel_size=3, strides=1, padding='same')(inputs)\n","    x = SubpixelConv2D(scale=2)(x)\n","    x = PReLU(shared_axes=[1,2])(x)\n","    return x\n","\n","def build_generator():\n","    inputs = Input(shape=(None, None, 3))\n","    x = Conv2D(filters=64, kernel_size=9, strides=1, padding='same')(inputs)\n","    x = PReLU(shared_axes=[1,2])(x)\n","    residual = x\n","    \n","    for _ in range(16):\n","        residual = residual_block(residual)\n","        \n","    x = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(residual)\n","    x = BatchNormalization()(x)\n","    x = Add()([x, residual])\n","    \n","    x = upscale_block(x)\n","    x = upscale_block(x)\n","    \n","    outputs = Conv2D(filters=3, kernel_size=9, strides=1, padding='same', activation='tanh')(x)\n","    \n","    \n","    return Model(inputs, outputs)\n","\n","def build_discriminator():\n","    model = tf.keras.Sequential([\n","        Conv2D(64, (3,3), strides=(1,1), padding='same', input_shape=(None, None, 3)),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(64, (3,3), strides=(2,2), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(128, (3,3), strides=(1,1), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(128, (3,3), strides=(2,2), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(256, (3,3), strides=(1,1), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(256, (3,3), strides=(2,2), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(512, (3,3), strides=(1,1), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(512, (3,3), strides=(2,2), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(1024, (3,3), strides=(1,1), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        Conv2D(1024, (3,3), strides=(2,2), padding='same'),\n","        LeakyReLU(alpha=0.2),\n","        GlobalMaxPooling2D(),\n","        Dense(1024),\n","        LeakyReLU(alpha=0.2),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    return model\n","\n","\n","\n","def build_srgan(generator):\n","  # Build and compile the discriminator\n","  discriminator = build_discriminator()\n","  discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4))\n","\n","  discriminator.trainable = False\n","\n","  # Define the inputs and outputs of the SRGAN model\n","  input_highres = Input(shape=(None,None,3))\n","  input_lowres = Input(shape=(None,None,3))\n","\n","  # Use the generator to create a super-resolution version of the low-resolution input\n","  generated_highres = generator(input_lowres)\n","\n","  # Feed the super-resolution image into the discriminator to determine if it is real or fake\n","  validity = discriminator(generated_highres)\n","\n","  # Define the full SRGAN model\n","  srgan = Model(inputs=[input_lowres, input_highres], outputs=[validity, generated_highres])\n","  srgan.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=Adam(lr=1e-4))\n","\n","  return srgan"],"metadata":{"id":"stI0LQG_50ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","import os\n","# Define the paths to the low- and high-resolution image directories\n","lr_image_dir = '/content/Data/HR'\n","hr_image_dir = '/content/Data/LR'\n","\n","# Load the image pairs into NumPy arrays\n","lr_images = []\n","hr_images = []\n","lr_images_vad = []\n","hr_images_vad = []\n","for i in range(80):\n","    # Load the low-resolution image\n","    lr_image_path = os.path.join(lr_image_dir, f'{i}.png')\n","    lr_image = np.asarray(Image.open(lr_image_path))\n","    lr_image = np.resize(lr_image, (256,256,3))\n","    lr_images.append(lr_image)\n","\n","    # Load the high-resolution image\n","    hr_image_path = os.path.join(hr_image_dir, f'{i}.png')\n","    hr_image = np.asarray(Image.open(hr_image_path))\n","    hr_image = np.resize(hr_image, (256,256,3))\n","    hr_images.append(hr_image)\n","for i in range(80, 100):\n","  # Load the low-resolution image\n","    lr_image_path = os.path.join(lr_image_dir, f'{i}.png')\n","    lr_image_vad = np.asarray(Image.open(lr_image_path))\n","    lr_image_vad = np.resize(lr_image_vad, (256,256,3))\n","    lr_images_vad.append(lr_image_vad)\n","\n","    # Load the high-resolution image\n","    hr_image_path = os.path.join(hr_image_dir, f'{i}.png')\n","    hr_image_vad = np.asarray(Image.open(hr_image_path))\n","    hr_image_vad = np.resize(hr_image_vad, (256,256,3))\n","    hr_images_vad.append(hr_image_vad)\n","\n","# Convert the lists to NumPy arrays\n","lr_images = np.array(lr_images)\n","hr_images = np.array(hr_images)\n","lr_images_vad = np.array(lr_images_vad)\n","hr_images_vad = np.array(hr_images_vad)\n","lr_images.shape"],"metadata":{"id":"CsMB78jw6aPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","# build the generator and discriminator models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","\n","# compile the discriminator model\n","discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4))\n","\n","# set the discriminator model to be non-trainable in the SRGAN model\n","discriminator.trainable = False\n","\n","# build the SRGAN model\n","srgan = build_srgan(generator)\n"],"metadata":{"id":"8ZdFkwu-6jnQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["srgan.summary()"],"metadata":{"id":"WSxY3Nrv4Zk6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator.summary()"],"metadata":{"id":"xL-lsep25Pxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator.summary()"],"metadata":{"id":"n75ieUBj5pLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["srgan.fit([lr_images,hr_images],[lr_images,np.ones(hr_images.shape)], batch_size=16, epochs=100)"],"metadata":{"id":"2-cnEm8z7Cor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BhZG79yB_fJC"},"execution_count":null,"outputs":[]}]}